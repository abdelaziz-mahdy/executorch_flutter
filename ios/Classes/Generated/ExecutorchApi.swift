// Autogenerated from Pigeon (v17.3.0), do not edit directly.
// See also: https://pub.dev/packages/pigeon

import Foundation

#if os(iOS)
  import Flutter
#elseif os(macOS)
  import FlutterMacOS
#else
  #error("Unsupported platform.")
#endif

private func wrapResult(_ result: Any?) -> [Any?] {
  return [result]
}

private func wrapError(_ error: Any) -> [Any?] {
  if let flutterError = error as? FlutterError {
    return [
      flutterError.code,
      flutterError.message,
      flutterError.details,
    ]
  }
  return [
    "\(error)",
    "\(type(of: error))",
    "Stacktrace: \(Thread.callStackSymbols)",
  ]
}

private func createConnectionError(withChannelName channelName: String) -> FlutterError {
  return FlutterError(code: "channel-error", message: "Unable to establish connection on channel: '\(channelName)'.", details: "")
}

private func isNullish(_ value: Any?) -> Bool {
  return value is NSNull || value == nil
}

private func nilOrValue<T>(_ value: Any?) -> T? {
  if value is NSNull { return nil }
  return value as! T?
}

/// Tensor data type enumeration
enum TensorType: Int {
  case float32 = 0
  case int8 = 1
  case int32 = 2
  case uint8 = 3
}

/// Model loading and execution states
enum ModelState: Int {
  case loading = 0
  case ready = 1
  case error = 2
  case disposed = 3
}

/// Inference execution status
enum InferenceStatus: Int {
  case success = 0
  case error = 1
  case timeout = 2
  case cancelled = 3
}

/// Tensor data for input/output
///
/// Generated class from Pigeon that represents data sent in messages.
struct TensorData {
  var shape: [Int64?]
  var dataType: TensorType
  var data: FlutterStandardTypedData
  var name: String? = nil

  static func fromList(_ list: [Any?]) -> TensorData? {
    let shape = list[0] as! [Int64?]
    let dataType = TensorType(rawValue: list[1] as! Int)!
    let data = list[2] as! FlutterStandardTypedData
    let name: String? = nilOrValue(list[3])

    return TensorData(
      shape: shape,
      dataType: dataType,
      data: data,
      name: name
    )
  }
  func toList() -> [Any?] {
    return [
      shape,
      dataType.rawValue,
      data,
      name,
    ]
  }
}

/// Inference request parameters
///
/// Generated class from Pigeon that represents data sent in messages.
struct InferenceRequest {
  var modelId: String
  var inputs: [TensorData?]
  var options: [String?: Any?]? = nil
  var timeoutMs: Int64? = nil
  var requestId: String? = nil

  static func fromList(_ list: [Any?]) -> InferenceRequest? {
    let modelId = list[0] as! String
    let inputs = list[1] as! [TensorData?]
    let options: [String?: Any?]? = nilOrValue(list[2])
    let timeoutMs: Int64? = isNullish(list[3]) ? nil : (list[3] is Int64? ? list[3] as! Int64? : Int64(list[3] as! Int32))
    let requestId: String? = nilOrValue(list[4])

    return InferenceRequest(
      modelId: modelId,
      inputs: inputs,
      options: options,
      timeoutMs: timeoutMs,
      requestId: requestId
    )
  }
  func toList() -> [Any?] {
    return [
      modelId,
      inputs,
      options,
      timeoutMs,
      requestId,
    ]
  }
}

/// Inference execution result
///
/// Generated class from Pigeon that represents data sent in messages.
struct InferenceResult {
  var status: InferenceStatus
  var executionTimeMs: Double
  var requestId: String? = nil
  var outputs: [TensorData?]? = nil
  var errorMessage: String? = nil
  var metadata: [String?: Any?]? = nil

  static func fromList(_ list: [Any?]) -> InferenceResult? {
    let status = InferenceStatus(rawValue: list[0] as! Int)!
    let executionTimeMs = list[1] as! Double
    let requestId: String? = nilOrValue(list[2])
    let outputs: [TensorData?]? = nilOrValue(list[3])
    let errorMessage: String? = nilOrValue(list[4])
    let metadata: [String?: Any?]? = nilOrValue(list[5])

    return InferenceResult(
      status: status,
      executionTimeMs: executionTimeMs,
      requestId: requestId,
      outputs: outputs,
      errorMessage: errorMessage,
      metadata: metadata
    )
  }
  func toList() -> [Any?] {
    return [
      status.rawValue,
      executionTimeMs,
      requestId,
      outputs,
      errorMessage,
      metadata,
    ]
  }
}

/// Model loading result
///
/// Generated class from Pigeon that represents data sent in messages.
struct ModelLoadResult {
  var modelId: String
  var state: ModelState
  var errorMessage: String? = nil

  static func fromList(_ list: [Any?]) -> ModelLoadResult? {
    let modelId = list[0] as! String
    let state = ModelState(rawValue: list[1] as! Int)!
    let errorMessage: String? = nilOrValue(list[2])

    return ModelLoadResult(
      modelId: modelId,
      state: state,
      errorMessage: errorMessage
    )
  }
  func toList() -> [Any?] {
    return [
      modelId,
      state.rawValue,
      errorMessage,
    ]
  }
}

private class ExecutorchHostApiCodecReader: FlutterStandardReader {
  override func readValue(ofType type: UInt8) -> Any? {
    switch type {
    case 128:
      return InferenceRequest.fromList(self.readValue() as! [Any?])
    case 129:
      return InferenceResult.fromList(self.readValue() as! [Any?])
    case 130:
      return ModelLoadResult.fromList(self.readValue() as! [Any?])
    case 131:
      return TensorData.fromList(self.readValue() as! [Any?])
    default:
      return super.readValue(ofType: type)
    }
  }
}

private class ExecutorchHostApiCodecWriter: FlutterStandardWriter {
  override func writeValue(_ value: Any) {
    if let value = value as? InferenceRequest {
      super.writeByte(128)
      super.writeValue(value.toList())
    } else if let value = value as? InferenceResult {
      super.writeByte(129)
      super.writeValue(value.toList())
    } else if let value = value as? ModelLoadResult {
      super.writeByte(130)
      super.writeValue(value.toList())
    } else if let value = value as? TensorData {
      super.writeByte(131)
      super.writeValue(value.toList())
    } else {
      super.writeValue(value)
    }
  }
}

private class ExecutorchHostApiCodecReaderWriter: FlutterStandardReaderWriter {
  override func reader(with data: Data) -> FlutterStandardReader {
    return ExecutorchHostApiCodecReader(data: data)
  }

  override func writer(with data: NSMutableData) -> FlutterStandardWriter {
    return ExecutorchHostApiCodecWriter(data: data)
  }
}

class ExecutorchHostApiCodec: FlutterStandardMessageCodec {
  static let shared = ExecutorchHostApiCodec(readerWriter: ExecutorchHostApiCodecReaderWriter())
}

/// Host API - Called from Dart to native platforms
/// Simplified to core operations: load, inference, dispose
///
/// Generated protocol from Pigeon that represents a handler of messages from Flutter.
protocol ExecutorchHostApi {
  /// Load a model from the specified file path
  /// Returns a unique model ID for subsequent operations
  func loadModel(filePath: String, completion: @escaping (Result<ModelLoadResult, Error>) -> Void)
  /// Run inference on a loaded model
  /// Returns inference results or error information
  func runInference(request: InferenceRequest, completion: @escaping (Result<InferenceResult, Error>) -> Void)
  /// Dispose a loaded model and free its resources
  /// User has full control over memory management
  func disposeModel(modelId: String) throws
  /// Get list of currently loaded model IDs
  func getLoadedModels() throws -> [String?]
  /// Enable or disable ExecuTorch debug logging
  /// Only works in debug builds
  func setDebugLogging(enabled: Bool) throws
}

/// Generated setup class from Pigeon to handle messages through the `binaryMessenger`.
class ExecutorchHostApiSetup {
  /// The codec used by ExecutorchHostApi.
  static var codec: FlutterStandardMessageCodec { ExecutorchHostApiCodec.shared }
  /// Sets up an instance of `ExecutorchHostApi` to handle messages through the `binaryMessenger`.
  static func setUp(binaryMessenger: FlutterBinaryMessenger, api: ExecutorchHostApi?) {
    /// Load a model from the specified file path
    /// Returns a unique model ID for subsequent operations
    let loadModelChannel = FlutterBasicMessageChannel(name: "dev.flutter.pigeon.executorch_flutter.ExecutorchHostApi.loadModel", binaryMessenger: binaryMessenger, codec: codec)
    if let api = api {
      loadModelChannel.setMessageHandler { message, reply in
        let args = message as! [Any?]
        let filePathArg = args[0] as! String
        api.loadModel(filePath: filePathArg) { result in
          switch result {
          case .success(let res):
            reply(wrapResult(res))
          case .failure(let error):
            reply(wrapError(error))
          }
        }
      }
    } else {
      loadModelChannel.setMessageHandler(nil)
    }
    /// Run inference on a loaded model
    /// Returns inference results or error information
    let runInferenceChannel = FlutterBasicMessageChannel(name: "dev.flutter.pigeon.executorch_flutter.ExecutorchHostApi.runInference", binaryMessenger: binaryMessenger, codec: codec)
    if let api = api {
      runInferenceChannel.setMessageHandler { message, reply in
        let args = message as! [Any?]
        let requestArg = args[0] as! InferenceRequest
        api.runInference(request: requestArg) { result in
          switch result {
          case .success(let res):
            reply(wrapResult(res))
          case .failure(let error):
            reply(wrapError(error))
          }
        }
      }
    } else {
      runInferenceChannel.setMessageHandler(nil)
    }
    /// Dispose a loaded model and free its resources
    /// User has full control over memory management
    let disposeModelChannel = FlutterBasicMessageChannel(name: "dev.flutter.pigeon.executorch_flutter.ExecutorchHostApi.disposeModel", binaryMessenger: binaryMessenger, codec: codec)
    if let api = api {
      disposeModelChannel.setMessageHandler { message, reply in
        let args = message as! [Any?]
        let modelIdArg = args[0] as! String
        do {
          try api.disposeModel(modelId: modelIdArg)
          reply(wrapResult(nil))
        } catch {
          reply(wrapError(error))
        }
      }
    } else {
      disposeModelChannel.setMessageHandler(nil)
    }
    /// Get list of currently loaded model IDs
    let getLoadedModelsChannel = FlutterBasicMessageChannel(name: "dev.flutter.pigeon.executorch_flutter.ExecutorchHostApi.getLoadedModels", binaryMessenger: binaryMessenger, codec: codec)
    if let api = api {
      getLoadedModelsChannel.setMessageHandler { _, reply in
        do {
          let result = try api.getLoadedModels()
          reply(wrapResult(result))
        } catch {
          reply(wrapError(error))
        }
      }
    } else {
      getLoadedModelsChannel.setMessageHandler(nil)
    }
    /// Enable or disable ExecuTorch debug logging
    /// Only works in debug builds
    let setDebugLoggingChannel = FlutterBasicMessageChannel(name: "dev.flutter.pigeon.executorch_flutter.ExecutorchHostApi.setDebugLogging", binaryMessenger: binaryMessenger, codec: codec)
    if let api = api {
      setDebugLoggingChannel.setMessageHandler { message, reply in
        let args = message as! [Any?]
        let enabledArg = args[0] as! Bool
        do {
          try api.setDebugLogging(enabled: enabledArg)
          reply(wrapResult(nil))
        } catch {
          reply(wrapError(error))
        }
      }
    } else {
      setDebugLoggingChannel.setMessageHandler(nil)
    }
  }
}
private class ExecutorchFlutterApiCodecReader: FlutterStandardReader {
  override func readValue(ofType type: UInt8) -> Any? {
    switch type {
    case 128:
      return InferenceResult.fromList(self.readValue() as! [Any?])
    case 129:
      return TensorData.fromList(self.readValue() as! [Any?])
    default:
      return super.readValue(ofType: type)
    }
  }
}

private class ExecutorchFlutterApiCodecWriter: FlutterStandardWriter {
  override func writeValue(_ value: Any) {
    if let value = value as? InferenceResult {
      super.writeByte(128)
      super.writeValue(value.toList())
    } else if let value = value as? TensorData {
      super.writeByte(129)
      super.writeValue(value.toList())
    } else {
      super.writeValue(value)
    }
  }
}

private class ExecutorchFlutterApiCodecReaderWriter: FlutterStandardReaderWriter {
  override func reader(with data: Data) -> FlutterStandardReader {
    return ExecutorchFlutterApiCodecReader(data: data)
  }

  override func writer(with data: NSMutableData) -> FlutterStandardWriter {
    return ExecutorchFlutterApiCodecWriter(data: data)
  }
}

class ExecutorchFlutterApiCodec: FlutterStandardMessageCodec {
  static let shared = ExecutorchFlutterApiCodec(readerWriter: ExecutorchFlutterApiCodecReaderWriter())
}

/// Flutter API - Called from native platforms to Dart (optional)
///
/// Generated protocol from Pigeon that represents Flutter messages that can be called from Swift.
protocol ExecutorchFlutterApiProtocol {
  /// Notify Dart about model loading progress (optional)
  func onModelLoadProgress(modelId modelIdArg: String, progress progressArg: Double, completion: @escaping (Result<Void, FlutterError>) -> Void)
  /// Notify Dart about inference completion (optional)
  func onInferenceComplete(requestId requestIdArg: String, result resultArg: InferenceResult, completion: @escaping (Result<Void, FlutterError>) -> Void)
}
class ExecutorchFlutterApi: ExecutorchFlutterApiProtocol {
  private let binaryMessenger: FlutterBinaryMessenger
  init(binaryMessenger: FlutterBinaryMessenger) {
    self.binaryMessenger = binaryMessenger
  }
  var codec: FlutterStandardMessageCodec {
    return ExecutorchFlutterApiCodec.shared
  }
  /// Notify Dart about model loading progress (optional)
  func onModelLoadProgress(modelId modelIdArg: String, progress progressArg: Double, completion: @escaping (Result<Void, FlutterError>) -> Void) {
    let channelName: String = "dev.flutter.pigeon.executorch_flutter.ExecutorchFlutterApi.onModelLoadProgress"
    let channel = FlutterBasicMessageChannel(name: channelName, binaryMessenger: binaryMessenger, codec: codec)
    channel.sendMessage([modelIdArg, progressArg] as [Any?]) { response in
      guard let listResponse = response as? [Any?] else {
        completion(.failure(createConnectionError(withChannelName: channelName)))
        return
      }
      if listResponse.count > 1 {
        let code: String = listResponse[0] as! String
        let message: String? = nilOrValue(listResponse[1])
        let details: String? = nilOrValue(listResponse[2])
        completion(.failure(FlutterError(code: code, message: message, details: details)))
      } else {
        completion(.success(Void()))
      }
    }
  }
  /// Notify Dart about inference completion (optional)
  func onInferenceComplete(requestId requestIdArg: String, result resultArg: InferenceResult, completion: @escaping (Result<Void, FlutterError>) -> Void) {
    let channelName: String = "dev.flutter.pigeon.executorch_flutter.ExecutorchFlutterApi.onInferenceComplete"
    let channel = FlutterBasicMessageChannel(name: channelName, binaryMessenger: binaryMessenger, codec: codec)
    channel.sendMessage([requestIdArg, resultArg] as [Any?]) { response in
      guard let listResponse = response as? [Any?] else {
        completion(.failure(createConnectionError(withChannelName: channelName)))
        return
      }
      if listResponse.count > 1 {
        let code: String = listResponse[0] as! String
        let message: String? = nilOrValue(listResponse[1])
        let details: String? = nilOrValue(listResponse[2])
        completion(.failure(FlutterError(code: code, message: message, details: details)))
      } else {
        completion(.success(Void()))
      }
    }
  }
}
