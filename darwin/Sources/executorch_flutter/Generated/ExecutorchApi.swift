// Autogenerated from Pigeon (v26.0.1), do not edit directly.
// See also: https://pub.dev/packages/pigeon

import Foundation

#if os(iOS)
  import Flutter
#elseif os(macOS)
  import FlutterMacOS
#else
  #error("Unsupported platform.")
#endif

/// Error class for passing custom error details to Dart side.
public final class PigeonError: Error {
  let code: String
  let message: String?
  let details: Sendable?

  public init(code: String, message: String?, details: Sendable?) {
    self.code = code
    self.message = message
    self.details = details
  }

  var localizedDescription: String {
    return
      "PigeonError(code: \(code), message: \(message ?? "<nil>"), details: \(details ?? "<nil>")"
  }
}

private func wrapResult(_ result: Any?) -> [Any?] {
  return [result]
}

private func wrapError(_ error: Any) -> [Any?] {
  if let pigeonError = error as? PigeonError {
    return [
      pigeonError.code,
      pigeonError.message,
      pigeonError.details,
    ]
  }
  if let flutterError = error as? FlutterError {
    return [
      flutterError.code,
      flutterError.message,
      flutterError.details,
    ]
  }
  return [
    "\(error)",
    "\(type(of: error))",
    "Stacktrace: \(Thread.callStackSymbols)",
  ]
}

private func isNullish(_ value: Any?) -> Bool {
  return value is NSNull || value == nil
}

private func nilOrValue<T>(_ value: Any?) -> T? {
  if value is NSNull { return nil }
  return value as! T?
}

func deepEqualsExecutorchApi(_ lhs: Any?, _ rhs: Any?) -> Bool {
  let cleanLhs = nilOrValue(lhs) as Any?
  let cleanRhs = nilOrValue(rhs) as Any?
  switch (cleanLhs, cleanRhs) {
  case (nil, nil):
    return true

  case (nil, _), (_, nil):
    return false

  case is (Void, Void):
    return true

  case let (cleanLhsHashable, cleanRhsHashable) as (AnyHashable, AnyHashable):
    return cleanLhsHashable == cleanRhsHashable

  case let (cleanLhsArray, cleanRhsArray) as ([Any?], [Any?]):
    guard cleanLhsArray.count == cleanRhsArray.count else { return false }
    for (index, element) in cleanLhsArray.enumerated() {
      if !deepEqualsExecutorchApi(element, cleanRhsArray[index]) {
        return false
      }
    }
    return true

  case let (cleanLhsDictionary, cleanRhsDictionary) as ([AnyHashable: Any?], [AnyHashable: Any?]):
    guard cleanLhsDictionary.count == cleanRhsDictionary.count else { return false }
    for (key, cleanLhsValue) in cleanLhsDictionary {
      guard cleanRhsDictionary.index(forKey: key) != nil else { return false }
      if !deepEqualsExecutorchApi(cleanLhsValue, cleanRhsDictionary[key]!) {
        return false
      }
    }
    return true

  default:
    // Any other type shouldn't be able to be used with pigeon. File an issue if you find this to be untrue.
    return false
  }
}

func deepHashExecutorchApi(value: Any?, hasher: inout Hasher) {
  if let valueList = value as? [AnyHashable] {
     for item in valueList { deepHashExecutorchApi(value: item, hasher: &hasher) }
     return
  }

  if let valueDict = value as? [AnyHashable: AnyHashable] {
    for key in valueDict.keys { 
      hasher.combine(key)
      deepHashExecutorchApi(value: valueDict[key]!, hasher: &hasher)
    }
    return
  }

  if let hashableValue = value as? AnyHashable {
    hasher.combine(hashableValue.hashValue)
  }

  return hasher.combine(String(describing: value))
}

    

/// Tensor data type enumeration
public enum TensorType: Int {
  case float32 = 0
  case int8 = 1
  case int32 = 2
  case uint8 = 3
}

/// Tensor data for input/output
///
/// Generated class from Pigeon that represents data sent in messages.
public struct TensorData: Hashable {
  var shape: [Int64?]
  var dataType: TensorType
  var data: FlutterStandardTypedData
  var name: String? = nil


  // swift-format-ignore: AlwaysUseLowerCamelCase
  static func fromList(_ pigeonVar_list: [Any?]) -> TensorData? {
    let shape = pigeonVar_list[0] as! [Int64?]
    let dataType = pigeonVar_list[1] as! TensorType
    let data = pigeonVar_list[2] as! FlutterStandardTypedData
    let name: String? = nilOrValue(pigeonVar_list[3])

    return TensorData(
      shape: shape,
      dataType: dataType,
      data: data,
      name: name
    )
  }
  func toList() -> [Any?] {
    return [
      shape,
      dataType,
      data,
      name,
    ]
  }
  public static func == (lhs: TensorData, rhs: TensorData) -> Bool {
    return deepEqualsExecutorchApi(lhs.toList(), rhs.toList())  }
  public func hash(into hasher: inout Hasher) {
    deepHashExecutorchApi(value: toList(), hasher: &hasher)
  }
}

/// Model loading result
/// On success: returns unique model ID
/// On failure: platform throws exception
///
/// Generated class from Pigeon that represents data sent in messages.
public struct ModelLoadResult: Hashable {
  var modelId: String


  // swift-format-ignore: AlwaysUseLowerCamelCase
  static func fromList(_ pigeonVar_list: [Any?]) -> ModelLoadResult? {
    let modelId = pigeonVar_list[0] as! String

    return ModelLoadResult(
      modelId: modelId
    )
  }
  func toList() -> [Any?] {
    return [
      modelId
    ]
  }
  public static func == (lhs: ModelLoadResult, rhs: ModelLoadResult) -> Bool {
    return deepEqualsExecutorchApi(lhs.toList(), rhs.toList())  }
  public func hash(into hasher: inout Hasher) {
    deepHashExecutorchApi(value: toList(), hasher: &hasher)
  }
}

private class ExecutorchApiPigeonCodecReader: FlutterStandardReader {
  override func readValue(ofType type: UInt8) -> Any? {
    switch type {
    case 129:
      let enumResultAsInt: Int? = nilOrValue(self.readValue() as! Int?)
      if let enumResultAsInt = enumResultAsInt {
        return TensorType(rawValue: enumResultAsInt)
      }
      return nil
    case 130:
      return TensorData.fromList(self.readValue() as! [Any?])
    case 131:
      return ModelLoadResult.fromList(self.readValue() as! [Any?])
    default:
      return super.readValue(ofType: type)
    }
  }
}

private class ExecutorchApiPigeonCodecWriter: FlutterStandardWriter {
  override func writeValue(_ value: Any) {
    if let value = value as? TensorType {
      super.writeByte(129)
      super.writeValue(value.rawValue)
    } else if let value = value as? TensorData {
      super.writeByte(130)
      super.writeValue(value.toList())
    } else if let value = value as? ModelLoadResult {
      super.writeByte(131)
      super.writeValue(value.toList())
    } else {
      super.writeValue(value)
    }
  }
}

private class ExecutorchApiPigeonCodecReaderWriter: FlutterStandardReaderWriter {
  override func reader(with data: Data) -> FlutterStandardReader {
    return ExecutorchApiPigeonCodecReader(data: data)
  }

  override func writer(with data: NSMutableData) -> FlutterStandardWriter {
    return ExecutorchApiPigeonCodecWriter(data: data)
  }
}

class ExecutorchApiPigeonCodec: FlutterStandardMessageCodec, @unchecked Sendable {
  static let shared = ExecutorchApiPigeonCodec(readerWriter: ExecutorchApiPigeonCodecReaderWriter())
}


/// Host API - Called from Dart to native platforms
/// Minimal interface matching native ExecuTorch: load → forward → dispose
/// Plus utility methods: getLoadedModels, setDebugLogging
/// All methods throw PlatformException on error
///
/// Generated protocol from Pigeon that represents a handler of messages from Flutter.
public protocol ExecutorchHostApi {
  /// Load a model from the specified file path
  /// Returns a unique model ID for subsequent operations
  /// Throws: PlatformException if file not found or model loading fails
  func load(filePath: String, completion: @escaping (Result<ModelLoadResult, Error>) -> Void)
  /// Run forward pass (inference) on a loaded model
  /// Returns output tensors directly (no wrapper object)
  /// Throws: PlatformException if model not found or inference fails
  func forward(modelId: String, inputs: [TensorData?], completion: @escaping (Result<[TensorData?], Error>) -> Void)
  /// Dispose a loaded model and free its resources
  /// User has full control over memory management
  /// Throws: PlatformException if model not found
  func dispose(modelId: String, completion: @escaping (Result<Void, Error>) -> Void)
  /// Get list of currently loaded model IDs
  /// Returns empty list if no models loaded
  func getLoadedModels(completion: @escaping (Result<[String?], Error>) -> Void)
  /// Enable or disable ExecuTorch debug logging
  /// Only works in debug builds
  func setDebugLogging(enabled: Bool, completion: @escaping (Result<Void, Error>) -> Void)
}

/// Generated setup class from Pigeon to handle messages through the `binaryMessenger`.
class ExecutorchHostApiSetup {
  static var codec: FlutterStandardMessageCodec { ExecutorchApiPigeonCodec.shared }
  /// Sets up an instance of `ExecutorchHostApi` to handle messages through the `binaryMessenger`.
  static func setUp(binaryMessenger: FlutterBinaryMessenger, api: ExecutorchHostApi?, messageChannelSuffix: String = "") {
    let channelSuffix = messageChannelSuffix.count > 0 ? ".\(messageChannelSuffix)" : ""
    /// Load a model from the specified file path
    /// Returns a unique model ID for subsequent operations
    /// Throws: PlatformException if file not found or model loading fails
    let loadChannel = FlutterBasicMessageChannel(name: "dev.flutter.pigeon.executorch_flutter.ExecutorchHostApi.load\(channelSuffix)", binaryMessenger: binaryMessenger, codec: codec)
    if let api = api {
      loadChannel.setMessageHandler { message, reply in
        let args = message as! [Any?]
        let filePathArg = args[0] as! String
        api.load(filePath: filePathArg) { result in
          switch result {
          case .success(let res):
            reply(wrapResult(res))
          case .failure(let error):
            reply(wrapError(error))
          }
        }
      }
    } else {
      loadChannel.setMessageHandler(nil)
    }
    /// Run forward pass (inference) on a loaded model
    /// Returns output tensors directly (no wrapper object)
    /// Throws: PlatformException if model not found or inference fails
    let forwardChannel = FlutterBasicMessageChannel(name: "dev.flutter.pigeon.executorch_flutter.ExecutorchHostApi.forward\(channelSuffix)", binaryMessenger: binaryMessenger, codec: codec)
    if let api = api {
      forwardChannel.setMessageHandler { message, reply in
        let args = message as! [Any?]
        let modelIdArg = args[0] as! String
        let inputsArg = args[1] as! [TensorData?]
        api.forward(modelId: modelIdArg, inputs: inputsArg) { result in
          switch result {
          case .success(let res):
            reply(wrapResult(res))
          case .failure(let error):
            reply(wrapError(error))
          }
        }
      }
    } else {
      forwardChannel.setMessageHandler(nil)
    }
    /// Dispose a loaded model and free its resources
    /// User has full control over memory management
    /// Throws: PlatformException if model not found
    let disposeChannel = FlutterBasicMessageChannel(name: "dev.flutter.pigeon.executorch_flutter.ExecutorchHostApi.dispose\(channelSuffix)", binaryMessenger: binaryMessenger, codec: codec)
    if let api = api {
      disposeChannel.setMessageHandler { message, reply in
        let args = message as! [Any?]
        let modelIdArg = args[0] as! String
        api.dispose(modelId: modelIdArg) { result in
          switch result {
          case .success:
            reply(wrapResult(nil))
          case .failure(let error):
            reply(wrapError(error))
          }
        }
      }
    } else {
      disposeChannel.setMessageHandler(nil)
    }
    /// Get list of currently loaded model IDs
    /// Returns empty list if no models loaded
    let getLoadedModelsChannel = FlutterBasicMessageChannel(name: "dev.flutter.pigeon.executorch_flutter.ExecutorchHostApi.getLoadedModels\(channelSuffix)", binaryMessenger: binaryMessenger, codec: codec)
    if let api = api {
      getLoadedModelsChannel.setMessageHandler { _, reply in
        api.getLoadedModels { result in
          switch result {
          case .success(let res):
            reply(wrapResult(res))
          case .failure(let error):
            reply(wrapError(error))
          }
        }
      }
    } else {
      getLoadedModelsChannel.setMessageHandler(nil)
    }
    /// Enable or disable ExecuTorch debug logging
    /// Only works in debug builds
    let setDebugLoggingChannel = FlutterBasicMessageChannel(name: "dev.flutter.pigeon.executorch_flutter.ExecutorchHostApi.setDebugLogging\(channelSuffix)", binaryMessenger: binaryMessenger, codec: codec)
    if let api = api {
      setDebugLoggingChannel.setMessageHandler { message, reply in
        let args = message as! [Any?]
        let enabledArg = args[0] as! Bool
        api.setDebugLogging(enabled: enabledArg) { result in
          switch result {
          case .success:
            reply(wrapResult(nil))
          case .failure(let error):
            reply(wrapError(error))
          }
        }
      }
    } else {
      setDebugLoggingChannel.setMessageHandler(nil)
    }
  }
}
