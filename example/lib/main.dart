/// ExecuTorch Flutter Example App
///
/// A comprehensive demonstration app showcasing ExecuTorch integration with Flutter,
/// featuring local model loading with camera-based real-time inference.
///
/// Features:
/// - Load ExecuTorch models from local assets (generated via python scripts)
/// - Platform-specific model optimization (CoreML/MPS for iOS, XNNPACK for Android)
/// - Real-time image classification with camera input
/// - Performance metrics and memory usage monitoring
/// - Model management with loading/unloading capabilities
/// - Cross-platform Android and iOS support
library;
import 'dart:io';
import 'dart:typed_data';
import 'dart:math' as math;

import 'package:flutter/material.dart';
import 'package:flutter/services.dart';
import 'package:camera/camera.dart';
import 'package:path_provider/path_provider.dart';
import 'package:image/image.dart' as img;

import 'package:executorch_flutter/executorch_flutter.dart';

void main() async {
  WidgetsFlutterBinding.ensureInitialized();

  // Initialize cameras for real-time inference demo
  final cameras = await availableCameras();

  runApp(ExecuTorchExampleApp(cameras: cameras));
}

class ExecuTorchExampleApp extends StatelessWidget {
  const ExecuTorchExampleApp({super.key, required this.cameras});

  final List<CameraDescription> cameras;

  @override
  Widget build(BuildContext context) {
    return MaterialApp(
      title: 'ExecuTorch Flutter Example',
      theme: ThemeData(
        colorScheme: ColorScheme.fromSeed(seedColor: Colors.deepPurple),
        useMaterial3: true,
      ),
      home: ExecuTorchHomePage(cameras: cameras),
    );
  }
}

class ExecuTorchHomePage extends StatefulWidget {
  const ExecuTorchHomePage({super.key, required this.cameras});

  final List<CameraDescription> cameras;

  @override
  State<ExecuTorchHomePage> createState() => _ExecuTorchHomePageState();
}

class _ExecuTorchHomePageState extends State<ExecuTorchHomePage> {
  final ExecutorchManager _executorchManager = ExecutorchManager.instance;

  // Model management
  final List<ModelInfo> _loadedModels = [];
  ModelInfo? _activeModel;
  bool _isLoading = false;

  // Camera and inference
  CameraController? _cameraController;
  bool _isCameraInitialized = false;
  bool _isInferenceRunning = false;

  // Results and performance
  String _lastInferenceResult = 'No inference run yet';
  double _lastInferenceTime = 0.0;
  String _memoryUsage = 'Unknown';

  // ImageNet class labels
  List<String> _imageNetLabels = [];

  // Local models generated by python/generate_test_models.py
  late final List<ModelSource> _demoModels;

  void _initializeDemoModels() {
    _demoModels = [
      // Simple demo model (works on all platforms)
      ModelSource(
        name: 'Simple Demo (Portable)',
        url: 'assets/models/simple_demo_portable.pte',
        type: ModelSourceType.asset,
        description: 'Basic test model for validation',
      ),

      // Platform-optimized models
      if (Platform.isIOS) ..._getIOSModels(),
      if (Platform.isAndroid) ..._getAndroidModels(),
    ];
  }

  List<ModelSource> _getIOSModels() {
    return [
      ModelSource(
        name: 'MobileNetV3 (CoreML)',
        url: 'assets/models/mobilenet_v3_small_ios_coreml.pte',
        type: ModelSourceType.asset,
        description: 'iOS Neural Engine optimized image classification',
      ),
      ModelSource(
        name: 'MobileNetV3 (MPS)',
        url: 'assets/models/mobilenet_v3_small_ios_mps.pte',
        type: ModelSourceType.asset,
        description: 'iOS Metal GPU accelerated image classification',
      ),
    ];
  }

  List<ModelSource> _getAndroidModels() {
    return [
      ModelSource(
        name: 'MobileNetV3 (XNNPACK)',
        url: 'assets/models/mobilenet_v3_small_android_cpu_xnnpack.pte',
        type: ModelSourceType.asset,
        description: 'Android CPU optimized image classification',
      ),
    ];
  }

  @override
  void initState() {
    super.initState();
    _initializeDemoModels();
    _loadImageNetLabels();
    _initializeExecutorchManager();
    _initializeCamera();
    _updateMemoryUsage();
  }

  Future<void> _loadImageNetLabels() async {
    try {
      final labelsData = await rootBundle.loadString('assets/models/imagenet_classes.txt');
      _imageNetLabels = labelsData.trim().split('\n');
      debugPrint('Loaded ${_imageNetLabels.length} ImageNet class labels');
    } catch (e) {
      debugPrint('Failed to load ImageNet labels: $e');
    }
  }

  Future<void> _initializeExecutorchManager() async {
    try {
      await _executorchManager.initialize();
      debugPrint('ExecutorchManager initialized successfully');
    } catch (e) {
      debugPrint('Failed to initialize ExecutorchManager: $e');
      setState(() {
        _lastInferenceResult = 'Failed to initialize ExecuTorch: $e';
      });
    }
  }

  @override
  void dispose() {
    _cameraController?.dispose();
    _disposeAllModels();
    super.dispose();
  }

  Future<void> _initializeCamera() async {
    if (widget.cameras.isEmpty) return;

    _cameraController = CameraController(
      widget.cameras.first,
      ResolutionPreset.medium,
      enableAudio: false,
    );

    try {
      await _cameraController!.initialize();
      setState(() {
        _isCameraInitialized = true;
      });
    } catch (e) {
      debugPrint('Camera initialization failed: $e');
      setState(() {
        _lastInferenceResult = 'Camera initialization failed - check console for details';
      });
    }
  }

  Future<void> _loadModel(ModelSource modelSource) async {
    if (_isLoading) return;

    setState(() {
      _isLoading = true;
    });

    try {
      // Load from local assets
      final modelPath = await _loadAssetModel(modelSource);

      // Load the model using ExecuTorch
      final model = await _executorchManager.loadModel(modelPath);

      final modelInfo = ModelInfo(
        model: model,
        source: modelSource,
        loadTime: DateTime.now(),
        filePath: modelPath,
      );

      setState(() {
        _loadedModels.add(modelInfo);
        _activeModel = modelInfo;
        _lastInferenceResult = 'Model loaded successfully: ${modelSource.name}';
      });

      _updateMemoryUsage();

    } catch (e) {
      debugPrint('Failed to load model ${modelSource.name}: $e');
      setState(() {
        _lastInferenceResult = 'Failed to load model: ${modelSource.name}';
      });
    } finally {
      setState(() {
        _isLoading = false;
      });
    }
  }

  Future<String> _loadAssetModel(ModelSource modelSource) async {
    final byteData = await rootBundle.load(modelSource.url);
    final directory = await getApplicationDocumentsDirectory();
    final fileName = modelSource.url.split('/').last;
    final file = File('${directory.path}/$fileName');

    await file.writeAsBytes(byteData.buffer.asUint8List());
    return file.path;
  }

  Future<void> _runInference() async {
    if (_activeModel == null || _isInferenceRunning || !_isCameraInitialized) {
      return;
    }

    setState(() {
      _isInferenceRunning = true;
    });

    try {
      // Capture image from camera
      final image = await _cameraController!.takePicture();
      final imageBytes = await File(image.path).readAsBytes();

      // Preprocess image for model input
      final tensorData = await _preprocessImage(imageBytes);

      // Run inference
      final startTime = DateTime.now();
      final result = await _activeModel!.model.runInference(inputs: [tensorData]);
      final endTime = DateTime.now();

      final inferenceTime = endTime.difference(startTime).inMilliseconds.toDouble();

      // Process results
      final prediction = _postprocessResults(result.outputs ?? []);

      setState(() {
        _lastInferenceResult = prediction;
        _lastInferenceTime = inferenceTime;
      });

      _updateMemoryUsage();

    } catch (e) {
      debugPrint('Inference failed: $e');
      setState(() {
        _lastInferenceResult = 'Inference failed - check console for details';
      });
    } finally {
      setState(() {
        _isInferenceRunning = false;
      });
    }
  }

  Future<TensorDataWrapper> _preprocessImage(Uint8List imageBytes) async {
    try {
      // Decode image
      final decodedImage = img.decodeImage(imageBytes);
      if (decodedImage == null) {
        debugPrint('Failed to decode image from camera');
        throw const ExecuTorchValidationException('Failed to decode image');
      }
      debugPrint('Successfully decoded image: ${decodedImage.width}x${decodedImage.height}');

      // Resize to model input size (224x224 for most image models)
      final resized = img.copyResize(decodedImage, width: 224, height: 224);

      // Convert to RGB if needed
      final rgbImage = resized.convert(numChannels: 3);

      // ImageNet normalization constants
      const mean = [0.485, 0.456, 0.406];
      const std = [0.229, 0.224, 0.225];

      // Create float32 tensor in NCHW format (1, 3, 224, 224)
      final floats = Float32List(1 * 3 * 224 * 224);

      // Fill tensor in NCHW format: [batch, channel, height, width]
      int index = 0;

      // Channel 0 (Red)
      for (int y = 0; y < 224; y++) {
        for (int x = 0; x < 224; x++) {
          final pixel = rgbImage.getPixel(x, y);
          final normalizedValue = (pixel.r / 255.0 - mean[0]) / std[0];
          floats[index++] = normalizedValue;
        }
      }

      // Channel 1 (Green)
      for (int y = 0; y < 224; y++) {
        for (int x = 0; x < 224; x++) {
          final pixel = rgbImage.getPixel(x, y);
          final normalizedValue = (pixel.g / 255.0 - mean[1]) / std[1];
          floats[index++] = normalizedValue;
        }
      }

      // Channel 2 (Blue)
      for (int y = 0; y < 224; y++) {
        for (int x = 0; x < 224; x++) {
          final pixel = rgbImage.getPixel(x, y);
          final normalizedValue = (pixel.b / 255.0 - mean[2]) / std[2];
          floats[index++] = normalizedValue;
        }
      }

      debugPrint('Preprocessed tensor: min=${floats.reduce((a, b) => a < b ? a : b).toStringAsFixed(3)}, max=${floats.reduce((a, b) => a > b ? a : b).toStringAsFixed(3)}');

      final tensorData = TensorDataWrapper(
        shape: [1, 3, 224, 224], // NCHW format
        dataType: TensorType.float32,
        data: floats.buffer.asUint8List(),
        name: 'input',
      );

      debugPrint('Successfully created tensor with shape: ${tensorData.shape}');
      return tensorData;
    } catch (e) {
      debugPrint('Error in image preprocessing: $e');
      rethrow;
    }
  }

  String _postprocessResults(List<TensorDataWrapper>? outputs) {
    if (outputs == null || outputs.isEmpty) {
      return 'No outputs received';
    }

    final output = outputs.first;

    // For classification models, find the class with highest probability
    if (output.dataType == TensorType.float32) {
      final byteData = ByteData.sublistView(output.data);
      final logits = <double>[];

      for (int i = 0; i < output.data.length ~/ 4; i++) {
        logits.add(byteData.getFloat32(i * 4, Endian.host));
      }

      debugPrint('Raw logits: first 5 = [${logits.take(5).map((e) => e.toStringAsFixed(3)).join(', ')}]');

      // Apply softmax to convert logits to probabilities
      final probabilities = _applySoftmax(logits);

      // Find top-5 predictions
      final indexed = List.generate(probabilities.length, (i) => MapEntry(i, probabilities[i]));
      indexed.sort((a, b) => b.value.compareTo(a.value));

      final top5 = indexed.take(5).toList();

      debugPrint('Top prediction: class ${top5.first.key}, confidence ${(top5.first.value * 100).toStringAsFixed(1)}%');

      // Build result string with labels if available
      if (_imageNetLabels.isNotEmpty) {
        final results = <String>[];
        for (int i = 0; i < top5.length; i++) {
          final index = top5[i].key;
          final prob = top5[i].value;
          final label = index < _imageNetLabels.length ? _imageNetLabels[index] : 'Unknown';
          final confidence = (prob * 100).toStringAsFixed(1);
          results.add('${i + 1}. $label ($confidence%)');
        }
        return 'Top predictions:\n${results.join('\n')}';
      } else {
        // Fallback to class indices if labels not loaded
        final topResult = top5.first;
        return 'Prediction: Class ${topResult.key} (confidence: ${(topResult.value * 100).toStringAsFixed(1)}%)';
      }
    }

    return 'Output shape: ${output.shape}, type: ${output.dataType}';
  }

  List<double> _applySoftmax(List<double> logits) {
    // Find max for numerical stability
    final maxLogit = logits.reduce((a, b) => a > b ? a : b);

    // Compute exp(logit - max) for each logit
    final expValues = logits.map((logit) => math.exp(logit - maxLogit)).toList();

    // Compute sum of all exp values
    final sumExp = expValues.reduce((a, b) => a + b);

    // Normalize to get probabilities
    return expValues.map((exp) => exp / sumExp).toList();
  }

  Future<void> _updateMemoryUsage() async {
    // This would typically get memory stats from the native platform
    // For now, we'll show a placeholder
    setState(() {
      _memoryUsage = '${_loadedModels.length} models loaded';
    });
  }

  Future<void> _disposeModel(ModelInfo modelInfo) async {
    try {
      await modelInfo.model.dispose();
      setState(() {
        _loadedModels.remove(modelInfo);
        if (_activeModel == modelInfo) {
          _activeModel = _loadedModels.isNotEmpty ? _loadedModels.last : null;
        }
      });
      _updateMemoryUsage();
      debugPrint('Successfully disposed model: ${modelInfo.source.name}');
    } catch (e) {
      debugPrint('Failed to dispose model ${modelInfo.source.name}: $e');
    }
  }

  Future<void> _disposeAllModels() async {
    for (final modelInfo in _loadedModels) {
      try {
        await modelInfo.model.dispose();
      } catch (e) {
        debugPrint('Failed to dispose model: $e');
      }
    }
    _loadedModels.clear();
    _activeModel = null;
  }

  @override
  Widget build(BuildContext context) {
    return Scaffold(
      appBar: AppBar(
        backgroundColor: Theme.of(context).colorScheme.inversePrimary,
        title: const Text('ExecuTorch Flutter Demo'),
        actions: [
          IconButton(
            icon: const Icon(Icons.memory),
            onPressed: _updateMemoryUsage,
            tooltip: 'Update Memory Usage',
          ),
        ],
      ),
      body: SingleChildScrollView(
        padding: const EdgeInsets.all(16.0),
        child: Column(
          crossAxisAlignment: CrossAxisAlignment.stretch,
          children: [
            // Model Management Section
            Card(
              child: Padding(
                padding: const EdgeInsets.all(16.0),
                child: Column(
                  crossAxisAlignment: CrossAxisAlignment.start,
                  children: [
                    Text(
                      'Model Management',
                      style: Theme.of(context).textTheme.headlineSmall,
                    ),
                    const SizedBox(height: 16),
                    Text('Memory Usage: $_memoryUsage'),
                    const SizedBox(height: 8),
                    Text('Active Model: ${_activeModel?.source.name ?? "None"}'),
                    const SizedBox(height: 16),
                    Wrap(
                      spacing: 8.0,
                      runSpacing: 8.0,
                      children: _demoModels.map((modelSource) {
                        final isLoaded = _loadedModels.any((m) => m.source.name == modelSource.name);
                        return ElevatedButton.icon(
                          onPressed: _isLoading || isLoaded ? null : () => _loadModel(modelSource),
                          icon: const Icon(Icons.storage),
                          label: Text(isLoaded ? '${modelSource.name} âœ“' : modelSource.name),
                        );
                      }).toList(),
                    ),
                  ],
                ),
              ),
            ),

            const SizedBox(height: 16),

            // Camera and Inference Section
            Card(
              child: Padding(
                padding: const EdgeInsets.all(16.0),
                child: Column(
                  crossAxisAlignment: CrossAxisAlignment.start,
                  children: [
                    Text(
                      'Real-time Inference',
                      style: Theme.of(context).textTheme.headlineSmall,
                    ),
                    const SizedBox(height: 16),
                    if (_isCameraInitialized && _cameraController != null)
                      SizedBox(
                        height: 300,
                        child: ClipRRect(
                          borderRadius: BorderRadius.circular(8.0),
                          child: CameraPreview(_cameraController!),
                        ),
                      )
                    else
                      Container(
                        height: 300,
                        decoration: BoxDecoration(
                          color: Colors.grey[300],
                          borderRadius: BorderRadius.circular(8.0),
                        ),
                        child: const Center(
                          child: Text('Camera not available'),
                        ),
                      ),
                    const SizedBox(height: 16),
                    ElevatedButton.icon(
                      onPressed: _activeModel != null && _isCameraInitialized && !_isInferenceRunning
                        ? _runInference
                        : null,
                      icon: _isInferenceRunning
                        ? const SizedBox(
                            width: 16,
                            height: 16,
                            child: CircularProgressIndicator(strokeWidth: 2),
                          )
                        : const Icon(Icons.psychology),
                      label: Text(_isInferenceRunning ? 'Running Inference...' : 'Run Inference'),
                    ),
                  ],
                ),
              ),
            ),

            const SizedBox(height: 16),

            // Results Section
            Card(
              child: Padding(
                padding: const EdgeInsets.all(16.0),
                child: Column(
                  crossAxisAlignment: CrossAxisAlignment.start,
                  children: [
                    Text(
                      'Results',
                      style: Theme.of(context).textTheme.headlineSmall,
                    ),
                    const SizedBox(height: 16),
                    Text('Last Inference Time: ${_lastInferenceTime.toStringAsFixed(1)}ms'),
                    const SizedBox(height: 8),
                    Text('Result: $_lastInferenceResult'),
                  ],
                ),
              ),
            ),

            const SizedBox(height: 16),

            // Loaded Models List
            if (_loadedModels.isNotEmpty)
              Card(
                child: Padding(
                  padding: const EdgeInsets.all(16.0),
                  child: Column(
                    crossAxisAlignment: CrossAxisAlignment.start,
                    children: [
                      Text(
                        'Loaded Models',
                        style: Theme.of(context).textTheme.headlineSmall,
                      ),
                      const SizedBox(height: 16),
                      ..._loadedModels.map((modelInfo) => ListTile(
                        title: Text(modelInfo.source.name),
                        subtitle: Text(modelInfo.source.description),
                        trailing: Row(
                          mainAxisSize: MainAxisSize.min,
                          children: [
                            if (_activeModel == modelInfo)
                              const Icon(Icons.check_circle, color: Colors.green),
                            IconButton(
                              icon: const Icon(Icons.delete),
                              onPressed: () => _disposeModel(modelInfo),
                            ),
                          ],
                        ),
                        onTap: () {
                          setState(() {
                            _activeModel = modelInfo;
                          });
                        },
                      )),
                    ],
                  ),
                ),
              ),
          ],
        ),
      ),
      floatingActionButton: _isLoading
        ? const FloatingActionButton(
            onPressed: null,
            child: CircularProgressIndicator(),
          )
        : null,
    );
  }
}

// Supporting classes
class ModelSource {
  const ModelSource({
    required this.name,
    required this.url,
    required this.type,
    required this.description,
  });

  final String name;
  final String url;
  final ModelSourceType type;
  final String description;
}

enum ModelSourceType { asset }

class ModelInfo {
  const ModelInfo({
    required this.model,
    required this.source,
    required this.loadTime,
    required this.filePath,
  });

  final ExecuTorchModel model;
  final ModelSource source;
  final DateTime loadTime;
  final String filePath;
}
