#!/usr/bin/env python3
"""
YOLO Model Export Script for ExecuTorch Flutter

This script exports YOLO models (YOLOv5, YOLOv8, YOLO11) to ExecuTorch format
using PyTorch's torch.export API (direct method, no ONNX needed).

Supported Models:
  - YOLOv5:  yolov5n, yolov5s, yolov5m, yolov5l, yolov5x
  - YOLOv8:  yolov8n, yolov8s, yolov8m, yolov8l, yolov8x
  - YOLO11:  yolo11n, yolo11s, yolo11m, yolo11l, yolo11x

Recommended for mobile: Nano (n) or Small (s) variants
"""

import torch
from pathlib import Path


def export_yolo_direct(model_name="yolo11n.pt", output_dir="../example/assets/models"):
    """
    Export YOLO model directly to ExecuTorch using torch.export (no ONNX needed).

    Args:
        model_name: YOLO model to export (e.g., "yolo11n.pt", "yolov8n.pt", "yolov5n.pt")
        output_dir: Output directory for .pte file
    """
    print(f"ðŸŽ¯ Exporting {model_name} to ExecuTorch (Direct Method)")
    print("=" * 70)

    try:
        from ultralytics import YOLO
        from executorch.exir import to_edge

        # Try to import XNNPACK partitioner for mobile optimization
        try:
            from executorch.backends.xnnpack.partition.xnnpack_partitioner import XnnpackPartitioner
            use_xnnpack = True
        except ImportError:
            print("âš ï¸  XNNPACK backend not available, using portable backend")
            use_xnnpack = False

        print(f"ðŸ“¥ Loading {model_name}...")
        yolo = YOLO(model_name)  # Downloads automatically if not present

        # Get the PyTorch model without NMS (required for ExecuTorch)
        model = yolo.model.eval().cpu()

        print("ðŸ”„ Exporting to torch.export format...")
        # Create example input (YOLO standard: 640x640)
        example_input = (torch.zeros(1, 3, 640, 640),)

        # Export to torch.export
        exported_program = torch.export.export(model, example_input)

        print("ðŸ”§ Converting to Edge IR...")
        edge_program = to_edge(exported_program)

        # Apply XNNPACK optimization if available
        if use_xnnpack:
            print("âš¡ Applying XNNPACK optimization for mobile...")
            edge_program = edge_program.to_backend(XnnpackPartitioner())
            backend_suffix = "xnnpack"
        else:
            backend_suffix = "portable"

        print("ðŸ“¦ Generating ExecuTorch program...")
        executorch_program = edge_program.to_executorch()

        # Create output filename
        model_base = model_name.replace('.pt', '')
        output_file = Path(output_dir) / f"{model_base}_{backend_suffix}.pte"
        output_file.parent.mkdir(parents=True, exist_ok=True)

        # Save to file
        with open(output_file, "wb") as f:
            executorch_program.write_to_file(f)

        file_size_mb = output_file.stat().st_size / (1024 * 1024)

        print("\n" + "=" * 70)
        print(f"âœ… Successfully exported!")
        print(f"   Output: {output_file}")
        print(f"   Size: {file_size_mb:.1f} MB")
        print(f"   Backend: {backend_suffix.upper()}")
        print("=" * 70)
        print("\nðŸ“ Model Info:")
        print(f"   Input:  [1, 3, 640, 640] (NCHW format, RGB, normalized [0,1])")
        print(f"   Output: [1, 84, 8400] (80 classes + 4 bbox coords)")
        print(f"   Note:   NMS must be applied in post-processing")
        print()

        return True

    except ImportError as e:
        print(f"\nâŒ Error: Missing dependency - {e}")
        print("\nInstall required packages:")
        print("  pip install torch")
        print("  pip install ultralytics")
        print("  pip install executorch")
        print()
        return False

    except Exception as e:
        print(f"\nâŒ Export failed: {e}")
        print("\nâš ï¸  YOLO models have known compatibility issues with torch.export")
        print("   due to dynamic operations (e.g., .item(), dynamic shapes).")
        print("\nWorkarounds:")
        print("  1. Export via ONNX format (see export_yolo_via_onnx)")
        print("  2. Use pre-converted YOLO models")
        print("  3. Simplify model by removing dynamic operations")
        print("\nFor now, you can:")
        print("  â€¢ Continue with MobileNet V3 for image classification")
        print("  â€¢ Export YOLO manually using ONNX workflow")
        print("  â€¢ Check for ExecuTorch updates with better YOLO support")
        print()
        return False


def export_yolo_via_onnx(model_name="yolo11n.pt", output_dir="../example/assets/models"):
    """
    Export YOLO to ExecuTorch via ONNX (fallback method).

    This is a two-step process:
    1. Export YOLO to ONNX
    2. Convert ONNX to ExecuTorch
    """
    print(f"ðŸŽ¯ Exporting {model_name} via ONNX (Fallback Method)")
    print("=" * 70)

    try:
        from ultralytics import YOLO

        print(f"ðŸ“¥ Loading {model_name}...")
        model = YOLO(model_name)

        print("ðŸ”„ Exporting to ONNX...")
        onnx_path = model.export(
            format='onnx',
            imgsz=640,
            simplify=True,
            dynamic=False  # ExecuTorch requires static shapes
        )

        print(f"âœ… ONNX export successful: {onnx_path}")
        print("\nðŸ“ Next Step: Convert ONNX to ExecuTorch")
        print("   Unfortunately, automatic ONNXâ†’ExecuTorch conversion is not")
        print("   currently available in this script.")
        print("\n   Manual conversion:")
        print("   1. Follow: https://pytorch.org/executorch/stable/tutorial-onnx-to-executorch.html")
        print("   2. Or use direct export method (recommended)")
        print()

        return onnx_path

    except Exception as e:
        print(f"âŒ ONNX export failed: {e}")
        return None


def print_usage_guide():
    """Print comprehensive usage guide."""
    print("""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                YOLO + ExecuTorch: Supported Versions
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

This script supports exporting the following YOLO models:

YOLOv5 (Ultralytics):
  â€¢ yolov5n.pt - Nano   (~4MB)  - Fastest, good for simple scenes
  â€¢ yolov5s.pt - Small  (~14MB) - Balanced speed and accuracy
  â€¢ yolov5m.pt - Medium (~40MB) - More accurate
  â€¢ yolov5l.pt - Large  (~90MB) - High accuracy (may be slow)
  â€¢ yolov5x.pt - XLarge (~170MB)- Best accuracy (not for mobile)

YOLOv8 (Ultralytics):
  â€¢ yolov8n.pt - Nano   (~6MB)  - Fastest, improved over v5
  â€¢ yolov8s.pt - Small  (~22MB) - Best balance for mobile
  â€¢ yolov8m.pt - Medium (~52MB) - High accuracy
  â€¢ yolov8l.pt - Large  (~88MB) - Very high accuracy
  â€¢ yolov8x.pt - XLarge (~138MB)- Best accuracy (not for mobile)

YOLO11 (Latest, Ultralytics):
  â€¢ yolo11n.pt - Nano   (~6MB)  - Fastest, best efficiency
  â€¢ yolo11s.pt - Small  (~22MB) - Recommended for mobile
  â€¢ yolo11m.pt - Medium (~52MB) - High accuracy
  â€¢ yolo11l.pt - Large  (~88MB) - Very high accuracy
  â€¢ yolo11x.pt - XLarge (~138MB)- Best accuracy (not for mobile)

Recommendation: Use Nano or Small variants for mobile devices.
                YOLO11 offers the best accuracy/speed tradeoff.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                        Export Methods
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Method 1: Direct Export (Recommended) â­
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Uses torch.export directly, no ONNX intermediate step needed.

  from export_yolo import export_yolo_direct
  export_yolo_direct("yolo11n.pt")

Method 2: Via ONNX (Fallback)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Two-step process: YOLO â†’ ONNX â†’ ExecuTorch

  from export_yolo import export_yolo_via_onnx
  export_yolo_via_onnx("yolo11n.pt")

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    Important Technical Details
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âš ï¸  NMS (Non-Maximum Suppression)
   Exported YOLO models do NOT include NMS. You must implement NMS in
   post-processing. The YoloProcessor class already handles this.

âš ï¸  Static Input Size
   ExecuTorch requires fixed 640x640 input. If you need different sizes,
   modify the export script's example_input dimensions.

âš ï¸  XNNPACK Backend
   XNNPACK provides significant speedup on mobile CPUs. Install with:
   pip install executorch[xnnpack]

ðŸ“Š Expected Performance (on mobile):
   â€¢ yolo11n/yolov8n: 50-100ms per frame (suitable for real-time)
   â€¢ yolo11s/yolov8s: 100-200ms per frame (good for video)
   â€¢ Larger models: 200ms+ (still images only)

ðŸ“ Model Input/Output Format:
   Input:  [1, 3, 640, 640] - NCHW, RGB, float32, range [0,1]
   Output: [1, 84, 8400] - 8400 predictions, each with 4 bbox + 80 classes

   Bbox format: [x_center, y_center, width, height] in image coordinates

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                        Usage in Flutter
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. Place exported .pte file in: example/assets/models/

2. Use YoloProcessor in your Flutter app:

   final processor = YoloProcessor(
     preprocessConfig: YoloPreprocessConfig(
       targetWidth: 640,
       targetHeight: 640,
     ),
     classLabels: cocoLabels,  // 80 COCO classes
     confidenceThreshold: 0.25,
     iouThreshold: 0.45,
   );

   final result = await processor.process(imageBytes, model);

3. COCO labels are automatically created by: python export_models.py

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

For more information:
  â€¢ ExecuTorch: https://pytorch.org/executorch/
  â€¢ Ultralytics: https://docs.ultralytics.com/
  â€¢ Flutter Guide: ../example/MODEL_EXPORT_GUIDE.md

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")


def main():
    """Main export workflow."""
    import sys

    print_usage_guide()

    # Check for command line arguments
    if len(sys.argv) > 1:
        model_name = sys.argv[1]
    else:
        # Default to YOLO11 Nano (latest and most efficient)
        model_name = "yolo11n.pt"
        print(f"\nðŸ’¡ No model specified, using default: {model_name}")
        print("   To specify a model: python export_yolo.py yolov8n.pt")

    print(f"\nðŸš€ Starting export for: {model_name}")
    print()

    # Try direct export first (recommended)
    success = export_yolo_direct(model_name)

    if not success:
        print("\nðŸ’¡ Attempting fallback method (ONNX)...")
        export_yolo_via_onnx(model_name)

    print("\n" + "=" * 70)
    print("ðŸ“‹ Next Steps:")
    print("  1. Verify .pte file exists in example/assets/models/")
    print("  2. Ensure COCO labels exist: python export_models.py")
    print("  3. Update model config in example/lib/screens/model_playground.dart")
    print("  4. Run Flutter app: cd example && flutter run")
    print("=" * 70)
    print()


if __name__ == "__main__":
    main()
